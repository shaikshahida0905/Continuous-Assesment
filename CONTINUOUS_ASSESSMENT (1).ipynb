{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**CONTINUOUS ASSESSMENT**"
      ],
      "metadata": {
        "id": "qNVEjvzne6sL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHAINED MULTI-OUTPUT CLASSIFICATION"
      ],
      "metadata": {
        "id": "zCdoZ9sSe2BM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w-yUz8ScVQHw"
      },
      "outputs": [],
      "source": [
        "#!pip install scikit-learn pandas\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/PubMed Multi Label Text Classification Dataset Processed.csv')"
      ],
      "metadata": {
        "id": "V5_N3h4gVujn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['Title'].fillna('') + ' ' + df['abstractText'].fillna('')"
      ],
      "metadata": {
        "id": "XfiHKn5dVw06"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text = df['text']\n",
        "y_type2 = df['A']\n",
        "y_type3 = df['B']\n",
        "y_type4 = df['C']"
      ],
      "metadata": {
        "id": "FhRybZ61Yyo2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=300)\n",
        "X = vectorizer.fit_transform(X_text)"
      ],
      "metadata": {
        "id": "YzkLrMO2VzFi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y2_train, y2_test, y3_train, y3_test, y4_train, y4_test = train_test_split(\n",
        "    X, y_type2, y_type3, y_type4, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "r4z3pnB8V2HA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LogisticRegression(max_iter=200)\n",
        "model1.fit(X_train, y2_train)\n",
        "y2_pred = model1.predict(X_test)"
      ],
      "metadata": {
        "id": "0owJBnXRV4Ja"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2 = pd.DataFrame(X_train.toarray())\n",
        "X_train_2['type2'] = y2_train.values\n",
        "\n",
        "X_test_2 = pd.DataFrame(X_test.toarray())\n",
        "X_test_2['type2'] = y2_pred\n",
        "\n",
        "X_train_2.columns = X_train_2.columns.astype(str)\n",
        "X_test_2.columns = X_test_2.columns.astype(str)"
      ],
      "metadata": {
        "id": "o4Yw0hCKV6t8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = LogisticRegression(max_iter=200)\n",
        "model2.fit(X_train_2, y3_train)\n",
        "y3_pred = model2.predict(X_test_2)"
      ],
      "metadata": {
        "id": "pWDZYUbcV8uv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_3 = X_train_2.copy()\n",
        "X_train_3['type3'] = y3_train.values\n",
        "\n",
        "X_test_3 = X_test_2.copy()\n",
        "X_test_3['type3'] = y3_pred\n",
        "\n",
        "X_train_3.columns = X_train_3.columns.astype(str)\n",
        "X_test_3.columns = X_test_3.columns.astype(str)"
      ],
      "metadata": {
        "id": "mZ5XoXm_cVm1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100)\n",
        "model3.fit(X_train_3, y4_train)\n",
        "y4_pred = model3.predict(X_test_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meg9eCfreamo",
        "outputId": "7ea956fd-8460-4898-a665-6d64972b069e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìå Classification Report - Type 2:\\n\")\n",
        "print(classification_report(y2_test, y2_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSvN6ReueavI",
        "outputId": "c466ad5a-327f-4d6d-bae6-c2270a1e3aed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Classification Report - Type 2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.82      0.78      5394\n",
            "           1       0.76      0.66      0.71      4606\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.75      0.75     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìå Classification Report - Type 3:\\n\")\n",
        "print(classification_report(y3_test, y3_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw70N6Yvecrv",
        "outputId": "7f06b719-96c9-4ffe-8a49-04897388c357"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Classification Report - Type 3:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.28      0.39       724\n",
            "           1       0.95      0.99      0.97      9276\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.79      0.63      0.68     10000\n",
            "weighted avg       0.92      0.94      0.92     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìå Classification Report - Type 4:\\n\")\n",
        "print(classification_report(y4_test, y4_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzJCu-Aqed8G",
        "outputId": "d24cd5d7-276f-4597-94a9-6046be3878a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìå Classification Report - Type 4:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.78      0.78      4716\n",
            "           1       0.81      0.80      0.81      5284\n",
            "\n",
            "    accuracy                           0.79     10000\n",
            "   macro avg       0.79      0.79      0.79     10000\n",
            "weighted avg       0.79      0.79      0.79     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hierarchical Structure"
      ],
      "metadata": {
        "id": "zbEJyFLkfE3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "tY0TfqXofFT8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/PubMed Multi Label Text Classification Dataset Processed.csv\")"
      ],
      "metadata": {
        "id": "YlR07rm7fp_H"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_text'] = df['Title'].fillna('') + \" \" + df['abstractText'].fillna('')\n",
        "df['meshMajor'] = df['meshMajor'].fillna('').apply(lambda x: x.split(','))"
      ],
      "metadata": {
        "id": "GCX91O8bftGr"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = [label for sublist in df['meshMajor'].tolist() for label in sublist]\n",
        "top_labels = [label for label, _ in Counter(all_labels).most_common(20)]\n",
        "df['meshMajor'] = df['meshMajor'].apply(lambda labels: [l for l in labels if l in top_labels])\n",
        "df = df[df['meshMajor'].map(len) > 0]"
      ],
      "metadata": {
        "id": "DUSrlESkf0zy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df['meshMajor'])"
      ],
      "metadata": {
        "id": "KR9kNv-Tf5Hu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = vectorizer.fit_transform(df['combined_text']).toarray()"
      ],
      "metadata": {
        "id": "G2bE3at-f8Eh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_all, y_test_all = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kOSF1lD6gCpD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_lvl1 = y_train_all[:, 0]\n",
        "y_test_lvl1 = y_test_all[:, 0]"
      ],
      "metadata": {
        "id": "ygiVsEo0gGDc"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = RandomForestClassifier(n_estimators=100)\n",
        "model1.fit(X_train, y_train_lvl1)\n",
        "y1_pred = model1.predict(X_test)"
      ],
      "metadata": {
        "id": "CrEU_eb_gLfO"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lvl2 = X_train[y_train_lvl1 == 1]\n",
        "y_train_lvl2 = y_train_all[y_train_lvl1 == 1, 1]\n",
        "X_test_lvl2 = X_test[y1_pred == 1]\n",
        "\n",
        "if len(X_train_lvl2) > 0 and len(X_test_lvl2) > 0:\n",
        "    model2 = GradientBoostingClassifier()\n",
        "    model2.fit(X_train_lvl2, y_train_lvl2)\n",
        "    y2_pred = model2.predict(X_test_lvl2)\n",
        "\n",
        "    # LEVEL 3 - further subset where Level 2 also predicted positive\n",
        "    X_train_lvl3 = X_train_lvl2[y_train_lvl2 == 1]\n",
        "    y_train_lvl3 = y_train_all[(y_train_lvl1 == 1) & (y_train_lvl2 == 1), 2]\n",
        "    X_test_lvl3 = X_test_lvl2[y2_pred == 1]\n",
        "\n",
        "    if len(X_train_lvl3) > 0 and len(X_test_lvl3) > 0:\n",
        "        model3 = MLPClassifier(hidden_layer_sizes=(64,), max_iter=100)\n",
        "        model3.fit(X_train_lvl3, y_train_lvl3)\n",
        "        y3_pred = model3.predict(X_test_lvl3)\n",
        "\n",
        "        print(\"‚úÖ Level 3 Evaluation Report:\")\n",
        "        print(classification_report(\n",
        "            y_test_all[(y1_pred == 1) & (y2_pred == 1), 2],\n",
        "            y3_pred\n",
        "        ))\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Not enough data for Level 3\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Not enough data for Level 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DlL3ayugPVN",
        "outputId": "5e7d73fb-3cac-47e6-ed55-81fed004603f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Not enough data for Level 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# ----------- LEVEL 1 REPORT -----------\n",
        "print(\"\\n‚úÖ Level 1 Report (Top Label: {})\".format(mlb.classes_[0]))\n",
        "print(classification_report(y_test_lvl1, y1_pred))\n",
        "print(\"Accuracy (Level 1):\", accuracy_score(y_test_lvl1, y1_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmmFu64LiSH4",
        "outputId": "228f556f-d715-46e9-9073-3335f87d6222"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Level 1 Report (Top Label:  'Adult')\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      1.00      0.94      7846\n",
            "           1       0.00      0.00      0.00      1027\n",
            "\n",
            "    accuracy                           0.88      8873\n",
            "   macro avg       0.44      0.50      0.47      8873\n",
            "weighted avg       0.78      0.88      0.83      8873\n",
            "\n",
            "Accuracy (Level 1): 0.884255606897329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}